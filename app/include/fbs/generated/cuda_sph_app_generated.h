// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_CUDASPHAPP_KIRI_FLATBUFFERS_H_
#define FLATBUFFERS_GENERATED_CUDASPHAPP_KIRI_FLATBUFFERS_H_

#include "flatbuffers/flatbuffers.h"

#include "app_data_generated.h"
#include "basic_types_generated.h"
#include "cuda_sph_data_generated.h"
#include "renderer_data_generated.h"

namespace KIRI {
namespace FlatBuffers {

struct CudaSphApp;
struct CudaSphAppBuilder;

struct CudaSphApp FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef CudaSphAppBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_SPH_DATA = 4,
    VT_SPH_SOLVER_TYPE = 6,
    VT_INIT_VOLUME = 8,
    VT_SPH_EMITTER = 10,
    VT_MAX_PARTICLES_NUM = 12,
    VT_APP_DATA = 14,
    VT_RENDERER_DATA = 16
  };
  const KIRI::FlatBuffers::CudaSphData *sph_data() const {
    return GetPointer<const KIRI::FlatBuffers::CudaSphData *>(VT_SPH_DATA);
  }
  KIRI::FlatBuffers::CudaSphType sph_solver_type() const {
    return static_cast<KIRI::FlatBuffers::CudaSphType>(GetField<int8_t>(VT_SPH_SOLVER_TYPE, 0));
  }
  const KIRI::FlatBuffers::SphInitBoxVolume *init_volume() const {
    return GetPointer<const KIRI::FlatBuffers::SphInitBoxVolume *>(VT_INIT_VOLUME);
  }
  const KIRI::FlatBuffers::CudaSphEmitter *sph_emitter() const {
    return GetPointer<const KIRI::FlatBuffers::CudaSphEmitter *>(VT_SPH_EMITTER);
  }
  uint32_t max_particles_num() const {
    return GetField<uint32_t>(VT_MAX_PARTICLES_NUM, 0);
  }
  const KIRI::FlatBuffers::AppData *app_data() const {
    return GetPointer<const KIRI::FlatBuffers::AppData *>(VT_APP_DATA);
  }
  const KIRI::FlatBuffers::SSFData *renderer_data() const {
    return GetPointer<const KIRI::FlatBuffers::SSFData *>(VT_RENDERER_DATA);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_SPH_DATA) &&
           verifier.VerifyTable(sph_data()) &&
           VerifyField<int8_t>(verifier, VT_SPH_SOLVER_TYPE) &&
           VerifyOffset(verifier, VT_INIT_VOLUME) &&
           verifier.VerifyTable(init_volume()) &&
           VerifyOffset(verifier, VT_SPH_EMITTER) &&
           verifier.VerifyTable(sph_emitter()) &&
           VerifyField<uint32_t>(verifier, VT_MAX_PARTICLES_NUM) &&
           VerifyOffset(verifier, VT_APP_DATA) &&
           verifier.VerifyTable(app_data()) &&
           VerifyOffset(verifier, VT_RENDERER_DATA) &&
           verifier.VerifyTable(renderer_data()) &&
           verifier.EndTable();
  }
};

struct CudaSphAppBuilder {
  typedef CudaSphApp Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_sph_data(flatbuffers::Offset<KIRI::FlatBuffers::CudaSphData> sph_data) {
    fbb_.AddOffset(CudaSphApp::VT_SPH_DATA, sph_data);
  }
  void add_sph_solver_type(KIRI::FlatBuffers::CudaSphType sph_solver_type) {
    fbb_.AddElement<int8_t>(CudaSphApp::VT_SPH_SOLVER_TYPE, static_cast<int8_t>(sph_solver_type), 0);
  }
  void add_init_volume(flatbuffers::Offset<KIRI::FlatBuffers::SphInitBoxVolume> init_volume) {
    fbb_.AddOffset(CudaSphApp::VT_INIT_VOLUME, init_volume);
  }
  void add_sph_emitter(flatbuffers::Offset<KIRI::FlatBuffers::CudaSphEmitter> sph_emitter) {
    fbb_.AddOffset(CudaSphApp::VT_SPH_EMITTER, sph_emitter);
  }
  void add_max_particles_num(uint32_t max_particles_num) {
    fbb_.AddElement<uint32_t>(CudaSphApp::VT_MAX_PARTICLES_NUM, max_particles_num, 0);
  }
  void add_app_data(flatbuffers::Offset<KIRI::FlatBuffers::AppData> app_data) {
    fbb_.AddOffset(CudaSphApp::VT_APP_DATA, app_data);
  }
  void add_renderer_data(flatbuffers::Offset<KIRI::FlatBuffers::SSFData> renderer_data) {
    fbb_.AddOffset(CudaSphApp::VT_RENDERER_DATA, renderer_data);
  }
  explicit CudaSphAppBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<CudaSphApp> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<CudaSphApp>(end);
    return o;
  }
};

inline flatbuffers::Offset<CudaSphApp> CreateCudaSphApp(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<KIRI::FlatBuffers::CudaSphData> sph_data = 0,
    KIRI::FlatBuffers::CudaSphType sph_solver_type = KIRI::FlatBuffers::CudaSphType_SPH,
    flatbuffers::Offset<KIRI::FlatBuffers::SphInitBoxVolume> init_volume = 0,
    flatbuffers::Offset<KIRI::FlatBuffers::CudaSphEmitter> sph_emitter = 0,
    uint32_t max_particles_num = 0,
    flatbuffers::Offset<KIRI::FlatBuffers::AppData> app_data = 0,
    flatbuffers::Offset<KIRI::FlatBuffers::SSFData> renderer_data = 0) {
  CudaSphAppBuilder builder_(_fbb);
  builder_.add_renderer_data(renderer_data);
  builder_.add_app_data(app_data);
  builder_.add_max_particles_num(max_particles_num);
  builder_.add_sph_emitter(sph_emitter);
  builder_.add_init_volume(init_volume);
  builder_.add_sph_data(sph_data);
  builder_.add_sph_solver_type(sph_solver_type);
  return builder_.Finish();
}

inline const KIRI::FlatBuffers::CudaSphApp *GetCudaSphApp(const void *buf) {
  return flatbuffers::GetRoot<KIRI::FlatBuffers::CudaSphApp>(buf);
}

inline const KIRI::FlatBuffers::CudaSphApp *GetSizePrefixedCudaSphApp(const void *buf) {
  return flatbuffers::GetSizePrefixedRoot<KIRI::FlatBuffers::CudaSphApp>(buf);
}

inline bool VerifyCudaSphAppBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifyBuffer<KIRI::FlatBuffers::CudaSphApp>(nullptr);
}

inline bool VerifySizePrefixedCudaSphAppBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifySizePrefixedBuffer<KIRI::FlatBuffers::CudaSphApp>(nullptr);
}

inline void FinishCudaSphAppBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<KIRI::FlatBuffers::CudaSphApp> root) {
  fbb.Finish(root);
}

inline void FinishSizePrefixedCudaSphAppBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<KIRI::FlatBuffers::CudaSphApp> root) {
  fbb.FinishSizePrefixed(root);
}

}  // namespace FlatBuffers
}  // namespace KIRI

#endif  // FLATBUFFERS_GENERATED_CUDASPHAPP_KIRI_FLATBUFFERS_H_
